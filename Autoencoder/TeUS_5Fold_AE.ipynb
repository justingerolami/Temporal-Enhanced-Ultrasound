{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To fix the GPU memory allocation issue\n",
    "import os\n",
    "#os.environ['TF_FORCE_GPU_ALLOW_GROWTH']='true'\n",
    "#os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.backend import clear_session\n",
    "\n",
    "#sklearn\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score, precision_score, recall_score,roc_curve, auc\n",
    "\n",
    "#others\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import itertools\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#There are 9 phantoms (9 labels) but we are only doing 3-way classifications, grouping on one variable\n",
    "#This function will change the labels to create 3 class labels\n",
    "def changeLabels(labels,oldclasses,newclass):\n",
    "    labels[labels==(oldclasses-1)]=newclass\n",
    "    return labels\n",
    "\n",
    "\n",
    "def normalizeData(data):\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(data.T)\n",
    "    return scaler.transform(data.T).T\n",
    "\n",
    "\n",
    "#Loads in each fold of a specified type. \n",
    "def loadFold(foldnum, type):\n",
    "    filePath = r\"C:\\Users\\Justin\\OneDrive - Queen's University\\MSc\\TeUS Focal Change Project\\data\\savedRF\\Jan17\\EMBC folds\\\\\"\n",
    "\n",
    "    if type=='moving':\n",
    "        filename = \"fold_\" + str(foldnum) + \".mat\"\n",
    "    elif type == 'fixed':\n",
    "        filename = \"fold_\" + str(foldnum) + \"_fixed.mat\"\n",
    "    else:\n",
    "        print(\"ERROR: LOADING FOLDS\")\n",
    "\n",
    "    fold = sio.loadmat(filePath+filename)\n",
    "    return fold\n",
    "\n",
    "\n",
    "#There are 9 total phantoms with 3 elasticitiy (E) and 3 scatterer sizes (S)\n",
    "#This function selects the 3 phantoms of specified properties to use\n",
    "def generatePhantomsToUse(type):\n",
    "    if type=='0p5EdiffS': return [1,2,3]\n",
    "    elif type=='1EdiffS': return [4,5,6]\n",
    "    elif type=='2EdiffS': return [7,8,9]\n",
    "    elif type=='23SdiffE': return [1,4,7]\n",
    "    elif type=='32SdiffE': return [2,5,8]\n",
    "    elif type=='60SdiffE': return [3,6,9]\n",
    "    elif type=='All': return [1,2,3,4,5,6,7,8,9]\n",
    "    else:\n",
    "        print(\"ERROR IN PHANTOMS TO USE\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(train_data, train_labels, val_data, val_labels, test_data, test_labels):\n",
    "    train_data = np.float32(train_data)\n",
    "    test_data = np.float32(test_data)\n",
    "    val_data = np.float32(val_data)\n",
    "    \n",
    "    num_classes = val_labels.shape[1]\n",
    "    \n",
    "    #model parameters\n",
    "    inputShape = 101\n",
    "    ae_s1_size = 80\n",
    "    ae_s2_size = 60\n",
    "    ae_s3_size = 30\n",
    "    latent_size = 15\n",
    "    cl_dense_size = 10\n",
    "    \n",
    "    #auto-encoder encoding->decoding\n",
    "    ENC1 = Dense(ae_s1_size, activation='relu', activity_regularizer=l2(0.0001))\n",
    "    ENC2 = Dense(ae_s2_size, activation='relu', activity_regularizer=l2(0.0001))\n",
    "    ENC3 = Dense(ae_s3_size, activation='relu', activity_regularizer=l2(0.0001))\n",
    "    ENC4 = Dense(latent_size, activation='relu', name='latent_out')\n",
    "    DEC1 = Dense(ae_s3_size, activation='relu', activity_regularizer=l2(0.0001))\n",
    "    DEC2 = Dense(ae_s2_size, activation='relu', activity_regularizer=l2(0.0001))\n",
    "    DEC3 = Dense(ae_s1_size, activation='relu', activity_regularizer=l2(0.0001))\n",
    "    DEC4 = Dense(inputShape, activation='sigmoid', name='ae_out')\n",
    "\n",
    "    #dense and classification layers\n",
    "    DENS1 = Dense(cl_dense_size, activation='relu', activity_regularizer=l2(0.00001))\n",
    "    CLASS = Dense(num_classes, activation='softmax', name='class_out')\n",
    "\n",
    "    #auto-encoder and the latent space inputs\n",
    "    input_ae = Input(shape=(inputShape,), name='ae_in')\n",
    "\n",
    "    #latent space (input->enc1->enc2->enc3->enc4->latent)\n",
    "    latent_ae = ENC4(ENC3(ENC2(ENC1( input_ae ))))\n",
    "    \n",
    "    #output of the ae (latent->dec1->dec2->dec3->dec4->output)\n",
    "    output_ae = DEC4(DEC3(DEC2(DEC1( latent_ae ))))\n",
    "    \n",
    "    #output of classification is (latent->dense->classification)\n",
    "    output_class = CLASS(DENS1( latent_ae ))\n",
    "\n",
    "    #3 models for training - only AE, full model (autoencoder-classifier), only classifier\n",
    "    autoencoder_alone = Model(input_ae, output_ae)\n",
    "    autoencoder_joint = Model(inputs=[input_ae], outputs=[output_ae, output_class])\n",
    "    classifier_alone = Model(input_ae, output_class)\n",
    "    \n",
    "    \n",
    "    \n",
    "    time_download_start = datetime.datetime.now()\n",
    "    \n",
    "    #uncomment block for training of only the autoencoder\n",
    "    #This may be used to first optimize the weights prior to joint training\n",
    "    '''\n",
    "    autoencoder_alone.compile(optimizer='adam',loss='mean_squared_error',metrics=['mse'])\n",
    "    history = autoencoder_alone.fit(train_data,train_data,\n",
    "                          validation_data=(val_data,val_data), \n",
    "                          epochs=500, batch_size=4096, shuffle=1, verbose=2,\n",
    "                          callbacks = [EarlyStopping(monitor='val_loss', mode='min', patience=30, restore_best_weights=True)])\n",
    "\n",
    "    pyplot.figure()\n",
    "    pyplot.plot(history.history['loss'], label='train')\n",
    "    pyplot.plot(history.history['val_loss'], label='test')\n",
    "    pyplot.legend()\n",
    "    pyplot.title('Autoencoder alone loss')\n",
    "    pyplot.show()\n",
    "\n",
    "    test1 = autoencoder_alone(test_data)\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    #uncomment this block for training of the autoencoder-classifier\n",
    "    autoencoder_joint.compile(optimizer='adam',\n",
    "                    loss={'ae_out':'mean_squared_error','class_out':'categorical_crossentropy'},\n",
    "                    loss_weights={'ae_out':1,'class_out':5},\n",
    "                    metrics={'ae_out':'mse','class_out':'accuracy'})\n",
    "    history = autoencoder_joint.fit({'ae_in':train_data},\n",
    "                    {'ae_out':train_data,'class_out':train_labels},\n",
    "                    validation_data=(val_data,[val_data,val_labels]), \n",
    "                    epochs=300, batch_size=1024, shuffle=1, verbose=0,\n",
    "                    callbacks = [EarlyStopping(monitor='val_loss', mode='min', patience=50, restore_best_weights=True)])\n",
    "\n",
    "    pyplot.figure()\n",
    "    pyplot.plot(history.history['loss'], label='train')\n",
    "    pyplot.plot(history.history['val_loss'], label='test')\n",
    "    pyplot.legend()\n",
    "    pyplot.title('Overal Loss')\n",
    "    pyplot.show()\n",
    "    \n",
    "    #generate the test predictions\n",
    "    test_pred = classifier_alone.predict(test_data)\n",
    "    y_test = np.argmax(test_labels,1)\n",
    "    y_pred = np.argmax(test_pred,1)\n",
    "    temp = np.max(test_pred, axis=1)<0\n",
    "    y_pred[temp] = np.max(y_test)+1\n",
    "    cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    acc=accuracy_score(y_test,y_pred)\n",
    "    precision = precision_score(y_test,y_pred, average='micro')\n",
    "    recall = recall_score(y_test,y_pred, average='micro')\n",
    "    \n",
    "    return acc, precision, recall, cnf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runModel(mode, trainingFoldsToUse, validationFoldToUse, testingFoldToUse, type):\n",
    "    #phantom names\n",
    "    phantomName1 = '0p5x 23u'\n",
    "    phantomName2 = '0p5x 32u'\n",
    "    phantomName3 = '0p5x 60u'\n",
    "    phantomName4 = '1x 23u'\n",
    "    phantomName5 = '1x 32u'\n",
    "    phantomName6 = '1x 60u'\n",
    "    phantomName7 = '23u 2x'\n",
    "    phantomName8= '32u 2x'\n",
    "    phantomName9= '60u 2x'\n",
    "    phantomNames = [phantomName1, phantomName2, phantomName3, phantomName4, phantomName5, phantomName6, \n",
    "                    phantomName7, phantomName8, phantomName9]\n",
    "    \n",
    "    #load each fold\n",
    "    #fold 6 is testing\n",
    "    fold1 = loadFold(1,type)\n",
    "    fold2 = loadFold(2,type)\n",
    "    fold3 = loadFold(3,type)\n",
    "    fold4 = loadFold(4,type)\n",
    "    fold5 = loadFold(5,type)\n",
    "    fold6 = loadFold(6,type)\n",
    "    \n",
    "    #select the phantoms to use for classification\n",
    "    phantomToUse = generatePhantomsToUse(mode)\n",
    "    phantomNames = [phantomNames[i-1] for i in phantomToUse]\n",
    "    \n",
    "    #Create training, validation, and testing sets\n",
    "    count=0\n",
    "    for i in range(len(trainingFoldsToUse)):\n",
    "        foldToAdd = eval(\"fold%s\"%trainingFoldsToUse[i])\n",
    "        for p in phantomToUse:\n",
    "            if count==0:\n",
    "                train_data = foldToAdd['p'+str(p)]\n",
    "                train_labels=foldToAdd['p'+str(p)+'c']\n",
    "            else:\n",
    "                train_data=np.concatenate((train_data, foldToAdd['p'+str(p)]), axis=0)\n",
    "                train_labels=np.concatenate((train_labels, foldToAdd['p'+str(p)+'c']), axis=0)\n",
    "            count+=1\n",
    "    \n",
    "    count=0\n",
    "    for i in range(len(validationFoldToUse)):\n",
    "        foldToAdd = eval(\"fold%s\"%validationFoldToUse[i])\n",
    "        for p in phantomToUse:\n",
    "            if count==0:\n",
    "                val_data = foldToAdd['p'+str(p)]\n",
    "                val_labels=foldToAdd['p'+str(p)+'c']\n",
    "            else:\n",
    "                val_data=np.concatenate((val_data, foldToAdd['p'+str(p)]), axis=0)\n",
    "                val_labels=np.concatenate((val_labels, foldToAdd['p'+str(p)+'c']), axis=0)\n",
    "            count+=1\n",
    "    \n",
    "    count=0\n",
    "    for i in range(len(testingFoldToUse)):\n",
    "        exec(\"foldToAdd=fold%s\"%testingFoldToUse[i])\n",
    "        for p in phantomToUse:\n",
    "            if count==0:\n",
    "                test_data = foldToAdd['p'+str(p)]\n",
    "                test_labels=foldToAdd['p'+str(p)+'c']\n",
    "            else:\n",
    "                test_data=np.concatenate((test_data, foldToAdd['p'+str(p)]), axis=0)\n",
    "                test_labels=np.concatenate((test_labels, foldToAdd['p'+str(p)+'c']), axis=0)\n",
    "            count+=1\n",
    "    \n",
    "    #normalization\n",
    "    train_data = normalizeData(train_data)\n",
    "    val_data = normalizeData(val_data)\n",
    "    test_data = normalizeData(test_data)\n",
    "    \n",
    "    #fix labels to be 0,1,2\n",
    "    train_labels = changeLabels(train_labels,phantomToUse[0],0)\n",
    "    train_labels = changeLabels(train_labels,phantomToUse[1],1)\n",
    "    train_labels = changeLabels(train_labels,phantomToUse[2],2)\n",
    "\n",
    "    test_labels = changeLabels(test_labels,phantomToUse[0],0)\n",
    "    test_labels = changeLabels(test_labels,phantomToUse[1],1)\n",
    "    test_labels = changeLabels(test_labels,phantomToUse[2],2)\n",
    "\n",
    "    val_labels = changeLabels(val_labels,phantomToUse[0],0)\n",
    "    val_labels = changeLabels(val_labels,phantomToUse[1],1)\n",
    "    val_labels = changeLabels(val_labels,phantomToUse[2],2)\n",
    "\n",
    "    #print(\"Train:      \", train_data.shape)\n",
    "    #print(\"Validation: \", val_data.shape)\n",
    "    #print(\"Test:       \", test_data.shape)\n",
    "\n",
    "    train_labels = to_categorical(train_labels)\n",
    "    val_labels = to_categorical(val_labels)\n",
    "    test_labels = to_categorical(test_labels)\n",
    "    #print(\"Train Labels:      \", train_labels.shape)\n",
    "    #print(\"Validation Labels: \", val_labels.shape)\n",
    "    #print(\"Test Labels:       \", test_labels.shape)\n",
    "    \n",
    "    #run the model\n",
    "    acc, precision, recall, cnf_matrix = model(train_data, train_labels, val_data, val_labels, test_data, test_labels)\n",
    "    return acc,precision, recall, cnf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode=['0p5EdiffS', '1EdiffS', '2EdiffS', '23SdiffE', '32SdiffE', '60SdiffE'];\n",
    "#testing set is fixed, so only 5 fold\n",
    "numFolds = 5\n",
    "\n",
    "#create list of folds to use for training & validation for each iteration\n",
    "trainingFoldsToUse = list(itertools.combinations(range(1, numFolds+1),numFolds-1))\n",
    "\n",
    "validationFoldToUse = []\n",
    "for i in range(numFolds):\n",
    "    validationFoldToUse.append(sorted(set(range(1,numFolds+1)) - set(trainingFoldsToUse[i]))) \n",
    "\n",
    "testingFoldToUse=[6];\n",
    "\n",
    "columns = ['Mode', 'Fold', 'Acc', 'Recall', 'Precision', 'ConfMat']\n",
    "movingFP = pd.DataFrame(index=None, columns=columns)\n",
    "fixedFP = pd.DataFrame(index=None, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#main\n",
    "for i in range(len(mode)):\n",
    "    for j in range(numFolds):\n",
    "        acc, prec, rec, conf = runModel(mode[i],trainingFoldsToUse[j], validationFoldToUse[j], testingFoldToUse, 'moving')\n",
    "        movingFP.loc[j+numFolds*(i)] = [mode[i], j, acc, prec, rec, conf]\n",
    "        clear_session()\n",
    "\n",
    "for i in range(len(mode)):\n",
    "    for j in range(numFolds):\n",
    "        acc, prec, rec, conf = runModel(mode[i],trainingFoldsToUse[j], validationFoldToUse[j], testingFoldToUse, 'fixed')\n",
    "        fixedFP.loc[j+numFolds*i] = [mode[i], j, acc, prec, rec, conf]\n",
    "        clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "filePath = r\"C:\\Users\\Justin\\OneDrive - Queen's University\\MSc\\TeUS Focal Change Project\\saved results\\\\\"\n",
    "\n",
    "movingFP.to_csv(filePath+\"EMBC_5folds_AE_moving.csv\")\n",
    "fixedFP.to_csv(filePath+\"EMBC_5folds_AE_fixed.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
